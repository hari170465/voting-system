# ğŸ—³ Voting System â€“ Full-Stack App
<p align="center">
  <img src="assets/page.png" alt="Voting System Banner" width="600">
</p>

A complete voting web application with:

- **Frontend:** Next.js + React  
- **Backend:** Express + Prisma + PostgreSQL  
- **Features:** User signup/login, single-vote enforcement, candidate management, results visualization (charts)  
- **Bonus:** Floating AI chat assistant powered by [Ollama](https://ollama.com/) (local LLM)

---

## ğŸ“¦ Prerequisites

| Tool             | Version / Notes |
|-----------------|----------------|
| [Node.js](https://nodejs.org/) | 20+ (LTS recommended) |
| npm             | Installed with Node |
| [Docker](https://www.docker.com/) | To run PostgreSQL |
| [Ollama](https://ollama.com/) *(optional)* | For local AI chat |

---

## ğŸ“ Project Structure
```bash
voting-system/
â”œâ”€â”€ backend/ 
â”œâ”€â”€ frontend/
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Environment Setup

### 1ï¸âƒ£ Clone & Install Dependencies

```bash
git clone https://github.com/<your-username>/voting-system.git
cd voting-system

# Root (installs orchestrator)
npm install

# Backend
cd backend && npm install

# Frontend
cd ../frontend && npm install
```

### 2ï¸âƒ£ Start PostgreSQL (via Docker)

Create the container (first time only):

```bash
docker run -d ^
  --name voting-postgres ^
  -e POSTGRES_USER=postgres ^
  -e POSTGRES_PASSWORD=postgres ^
  -e POSTGRES_DB=votingdb ^
  -p 5432:5432 ^
  postgres:16
```

Subsequent runs:
```bash
docker start voting-postgres
```

### 3ï¸âƒ£ Backend Environment (backend/.env)
```ini
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/votingdb?schema=public"
JWT_SECRET="change_me"
CORS_ORIGIN="http://localhost:3000"
NODE_ENV="development"
PORT=4000
OLLAMA_MODEL="llama3.2"   # Optional
```

Apply migrations:
```bash
cd backend
npx prisma migrate dev --name init
```

(Optional) Open DB GUI to add candidates manually:
```bash
npx prisma studio
```

### 4ï¸âƒ£ Frontend Environment (frontend/.env.local)
```ini
NEXT_PUBLIC_API_BASE_URL=http://localhost:4000/api
```
### 5ï¸âƒ£ (Optional) Setup AI Chat with Ollama
Download Ollama: https://ollama.com/download

Pull a model:

```bash
ollama pull llama3.2
```

## ğŸš€ Running Locally

From the project **root**:

### Backend + Frontend only
```bash
npm run dev
```
Then opem http://localhost:3000 in the browser

## ğŸ§ª Features
- âœ… Signup & Login: /signup and /login
- âœ… Vote: /vote (only once per user)
- âœ… View Results: /results (live chart)
- âœ… Admin Panel: /admin (add/remove candidates)
- âœ… Chat: Floating button â†’ /chat (AI helper answers setup/deploy questions)

## ğŸ‘¥ Contributors
- Built by **Hariharasudan Muralidaran**